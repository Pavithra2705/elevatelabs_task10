Project Overview

This project implements a K-Nearest Neighbors (KNN) classifier to recognize handwritten digits using the Sklearn Digits dataset. The goal is to understand distance-based classification, feature scaling, K tuning, and model evaluation.

ğŸ“‚ Dataset

Source: Sklearn Digits Dataset (load_digits())

Samples: 1797 images

Image Size: 8 Ã— 8 pixels

Classes: Digits (0â€“9)

ğŸ›  Tools & Libraries Used

Python

Scikit-learn

NumPy

Matplotlib

ğŸš€ Steps Performed
1ï¸âƒ£ Data Loading

Loaded the digits dataset and examined feature and label shapes.

2ï¸âƒ£ Data Visualization

Displayed sample images to confirm correct digit-label mapping.

3ï¸âƒ£ Train-Test Split

Split dataset into:

80% Training

20% Testing

4ï¸âƒ£ Feature Scaling

Applied StandardScaler to normalize features since KNN uses distance metrics.

5ï¸âƒ£ Model Training

Trained KNN classifier with multiple values of K:

K = 3

K = 5

K = 7

K = 9

6ï¸âƒ£ Model Evaluation

Compared accuracy for different K values

Selected best K based on highest accuracy

7ï¸âƒ£ Confusion Matrix

Generated confusion matrix to analyze misclassifications.

8ï¸âƒ£ Predictions

Displayed test images with predicted labels.

ğŸ“Š Results

Best Accuracy Achieved: ~98% (may vary slightly)

Model performs well in recognizing handwritten digits

Minor confusion observed between visually similar digits

ğŸ“ˆ Accuracy vs K Graph

Shows how model performance varies with different K values and helps in selecting the optimal K.

ğŸ” Confusion Matrix Insights

Most digits correctly classified

Some errors between similar shapes (e.g., 3 & 5, 8 & 9)

ğŸ¯ Key Learnings

âœ” KNN is a distance-based classifier
âœ” Feature scaling is critical for performance
âœ” Optimal K improves accuracy
âœ” Confusion matrix helps understand errors

ğŸ’¡ Interview Questions & Answers
â“ What is K in KNN?

K represents the number of nearest neighbors used to classify a new data point.

â“ Why is scaling required for KNN?

Because KNN uses distance metrics, unscaled features may dominate and reduce accuracy.

â“ What is Euclidean Distance?

The straight-line distance between two points:

d = âˆšÎ£(x1 - x2)Â²

â“ What happens if K is too low?

Sensitive to noise

Overfitting

High variance

â“ Limitations of KNN

Slow for large datasets

Memory intensive

Sensitive to noise

Affected by feature scaling

ğŸ“ Repository Contents

knn_digits.ipynb â†’ Jupyter Notebook

README.md â†’ Project documentation

Screenshots of results (plots & confusion matrix)

âœ… Conclusion

The KNN classifier effectively recognizes handwritten digits with high accuracy. Proper feature scaling and K tuning significantly improve model performance.
